{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'dgl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-c68ee2ba481e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mdgl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcsr_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoo_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'dgl'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import dgl\n",
    "import torch\n",
    "from scipy.sparse import csr_matrix, coo_matrix \n",
    "import numpy as np\n",
    "import dgl.function as fn\n",
    "import dgl.nn as dglnn\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import dgl.function as fn\n",
    "import dgl.nn.pytorch as dglnn\n",
    "import time\n",
    "import argparse\n",
    "from dgl.data import *\n",
    "import tqdm\n",
    "from sklearn import metrics\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/dqw_zyf/GraphDTI/code\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())\n",
    "os.chdir('/home/dqw_zyf/DTI/data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alldata = pd.read_csv('alldata.csv') #491718\n",
    "tar_embeddings = pd.read_csv('corpus2_tar_embeddings.csv')\n",
    "mol_embeddings = pd.read_csv('corpus2_mol_embeddings.csv')\n",
    "\n",
    "alldata.drop_duplicates(inplace = True)\n",
    "alldata = alldata[(alldata.notna())] #462361"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "462361"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(alldata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "462361\n",
      "462361\n",
      "462361\n"
     ]
    }
   ],
   "source": [
    "data = pd.merge(alldata,tar_embeddings)\n",
    "print(len(data))\n",
    "data1 = pd.merge(data,mol_embeddings)\n",
    "print(len(data1))\n",
    "data1.drop_duplicates(inplace = True)\n",
    "data1 = data1[(data1.notna())] #462361\n",
    "print(len(data1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "281876"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data1['mol'].unique())#281876"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5099"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data1['tar_id'].unique()) #5099"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#转变成边分类任务\n",
    "#index = data1['labels'] #239903  \n",
    "index_np = np.array(data1[['mol_id','tar_id']])\n",
    "index_dict = list(map(tuple, index_np))\n",
    "\n",
    "reindex_np =  np.array(data1[['tar_id','mol_id']])\n",
    "reindex_dict = list(map(tuple, reindex_np))\n",
    "##生成图\n",
    "g = dgl.heterograph({  ('mol', 'links', 'tar'): (index_dict),\n",
    "                         ('tar', 'links-by', 'mol'): (reindex_dict)                                     } )\n",
    "\n",
    "#graph(num_nodes={'mol': 281876, 'tar': 5099},\n",
    "#      num_edges={('mol', 'links', 'tar'): 462361},\n",
    "#      metagraph=[('mol', 'tar', 'links')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph(num_nodes={'mol': 281876, 'tar': 5099},\n",
       "      num_edges={('mol', 'links', 'tar'): 462361, ('tar', 'links-by', 'mol'): 462361},\n",
       "      metagraph=[('mol', 'tar', 'links'), ('tar', 'mol', 'links-by')])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#节点特征\n",
    "\n",
    "mol_feats = np.array(mol_embeddings.iloc[:,1:101])\n",
    "mol_feats = list(map(tuple, mol_feats))\n",
    "\n",
    "tar_feats = np.array(tar_embeddings.iloc[:,1:101])\n",
    "tar_feats = list(map(tuple,tar_feats))\n",
    "\n",
    "g.nodes['mol'].data['feats'] = torch.Tensor(mol_feats)\n",
    "g.nodes['tar'].data['feats'] = torch.Tensor(tar_feats)\n",
    "\n",
    "\n",
    "##边的标签\n",
    "g.edges['links'].data['label'] = torch.Tensor(np.array(data1['labels']))\n",
    "\n",
    "\n",
    "# 进行训练、验证和测试集划分\n",
    "train_index = data1[data1['Curation/DataSource']=='ChEMBL'].index ##399553\n",
    "val_index = data1[data1['Curation/DataSource']=='Curated from the literature by BindingDB'].index ##4022\n",
    "test_index =  data1[data1['Curation/DataSource']=='PubChem'].index\n",
    "\n",
    "train_mask = np.zeros((462361),dtype = int)\n",
    "\n",
    "for i in train_index:\n",
    "    train_mask[i] = 1\n",
    "\n",
    "val_mask = np.zeros((462361),dtype = int)\n",
    "for i in val_index:\n",
    "    val_mask[i] = 1\n",
    "\n",
    "test_mask = np.zeros((462361),dtype = int)\n",
    "for i in test_index:\n",
    "    test_mask[i] = 1    \n",
    "\n",
    "g.edges['links'].data['train_mask'] = torch.BoolTensor(np.asarray(train_mask).astype(bool))\n",
    "g.edges['links'].data['val_mask'] = torch.BoolTensor(np.asarray(val_mask).astype(bool))\n",
    "g.edges['links'].data['test_mask'] = torch.BoolTensor(np.asarray(test_mask).astype(bool))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a Heterograph Conv model\n",
    "\n",
    "class RGCN(nn.Module):\n",
    "    def __init__(self, in_feats, hid_feats, out_feats, rel_names):\n",
    "        super().__init__()\n",
    "        # 实例化HeteroGraphConv，in_feats是输入特征的维度，out_feats是输出特征的维度，aggregate是聚合函数的类型\n",
    "        self.conv1 = dglnn.HeteroGraphConv({\n",
    "            rel: dglnn.GraphConv(in_feats, hid_feats)\n",
    "            for rel in rel_names}, aggregate='sum')\n",
    "        self.conv2 = dglnn.HeteroGraphConv({\n",
    "            rel: dglnn.GraphConv(hid_feats, out_feats)\n",
    "            for rel in rel_names}, aggregate='sum')\n",
    "\n",
    "    def forward(self, graph, inputs):\n",
    "        # 输入是节点的特征字典\n",
    "        h = self.conv1(graph, inputs)\n",
    "        h = {k: F.relu(v) for k, v in h.items()}\n",
    "        h = self.conv2(graph, h)\n",
    "        return h\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, in_features, hidden_features, out_features, rel_names):\n",
    "        super().__init__()\n",
    "        self.sage = RGCN(in_features, hidden_features, out_features, rel_names)\n",
    "        self.pred = HeteroDotProductPredictor()\n",
    "    def forward(self, g, x, etype):\n",
    "        h = self.sage(g, x)\n",
    "        return self.pred(g, h, etype)\n",
    "\n",
    "class HeteroDotProductPredictor(nn.Module):\n",
    "    def forward(self, graph, h, etype):\n",
    "        # h是从5.1节中对每种类型的边所计算的节点表示\n",
    "        with graph.local_scope():\n",
    "            graph.ndata['h'] = h   #一次性为所有节点类型的 'h'赋值\n",
    "            graph.apply_edges(fn.u_dot_v('h', 'h', 'score'), etype=etype)\n",
    "            return graph.edges[etype].data['score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Model(100, 20, 2, g.etypes)\n",
    "mol_feats = g.nodes['mol'].data['feats']\n",
    "tar_feats = g.nodes['tar'].data['feats']\n",
    "label = g.edges['links'].data['label']\n",
    "train_mask = g.edges['links'].data['train_mask']\n",
    "node_features = {'mol': mol_feats, 'tar': tar_feats}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 0., 1.,  ..., 0., 1., 1.])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label[train_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "type Tensor doesn't define __round__ method",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m#loss_fcn = nn.CrossEntropyLoss()\u001b[39;00m\n\u001b[1;32m      7\u001b[0m loss \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mBCEWithLogitsLoss(reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msum\u001b[39m\u001b[38;5;124m'\u001b[39m)(pred[train_mask], label[train_mask])\n\u001b[0;32m----> 8\u001b[0m acc \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28;43mround\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpred\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m==\u001b[39m labels)\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39msum() \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(pred)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m#loss = loss_fcn(pred[train_mask],label[train_mask])\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m#loss = (abs(pred[train_mask] - label[train_mask])).mean()\u001b[39;00m\n\u001b[1;32m     11\u001b[0m opt\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "\u001b[0;31mTypeError\u001b[0m: type Tensor doesn't define __round__ method"
     ]
    }
   ],
   "source": [
    "opt = torch.optim.Adam(model.parameters())\n",
    "for epoch in range(1000):\n",
    "    logits = model(g, node_features, 'links')\n",
    "    pred =  pred.squeeze()\n",
    "  \n",
    "    #loss_fcn = nn.CrossEntropyLoss()\n",
    "    #loss = torch.nn.BCEWithLogitsLoss(reduction='sum')(pred[train_mask], label[train_mask])\n",
    "    #acc = (round(pred) == labels).float().sum() / len(pred)\n",
    "    #loss = loss_fcn(pred[train_mask],label[train_mask])\n",
    "    #loss = (abs(pred[train_mask] - label[train_mask])).mean()\n",
    "    opt.zero_grad()\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    print(loss.item(),acc.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class HeteroMLPPredictor(nn.Module):\n",
    "    def __init__(self, in_dims, n_classes):\n",
    "        super().__init__()\n",
    "        self.W = nn.Linear(in_dims * 2, n_classes)\n",
    "\n",
    "    def apply_edges(self, edges):\n",
    "        x = torch.cat([edges.src['h'], edges.dst['h']], 1)\n",
    "        y = self.W(x)\n",
    "        return {'score': y}\n",
    "\n",
    "    def forward(self, graph, h):\n",
    "        # h是从5.1节中对异构图的每种类型的边所计算的节点表示\n",
    "        with graph.local_scope():\n",
    "            graph.ndata['h'] = h   #一次性为所有节点类型的 'h'赋值\n",
    "            graph.apply_edges(self.apply_edges)\n",
    "            return graph.edata['score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Model2(nn.Module):\n",
    "    def __init__(self, in_features, hidden_features, out_features, rel_names):\n",
    "        super().__init__()\n",
    "        self.sage = RGCN(in_features, hidden_features, out_features, rel_names)\n",
    "        self.pred = HeteroMLPPredictor(out_features, len(rel_names))\n",
    "    def forward(self, g, x, dec_graph):\n",
    "        h = self.sage(g, x)\n",
    "        return self.pred(dec_graph, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dec_graph = g['mol', :, 'tar']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['links', 'links-by']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.etypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph(num_nodes={'mol': 281876, 'tar': 5099},\n",
       "      num_edges={('mol', 'links', 'tar'): 462361},\n",
       "      metagraph=[('mol', 'tar', 'links')])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "276374.0625\n",
      "276374.0625\n",
      "276374.0625\n",
      "276374.0625\n",
      "276374.0625\n",
      "276374.0625\n",
      "276374.0625\n",
      "276374.0625\n",
      "276374.0625\n",
      "276374.0625\n",
      "276374.0625\n",
      "276374.0625\n",
      "276374.0625\n",
      "276374.0625\n",
      "276374.0625\n",
      "276374.0625\n",
      "276374.0625\n",
      "276374.0625\n",
      "276374.0625\n",
      "276374.0625\n",
      "276374.0625\n",
      "276374.0625\n",
      "276374.0625\n",
      "276374.0625\n",
      "276374.0625\n",
      "276374.0625\n",
      "276374.0625\n",
      "276374.0625\n",
      "276374.0625\n",
      "276374.0625\n",
      "276374.0625\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[81], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m loss \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mBCEWithLogitsLoss(reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msum\u001b[39m\u001b[38;5;124m'\u001b[39m)(logits[train_mask], label[train_mask])\n\u001b[1;32m     13\u001b[0m opt\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 14\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m opt\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(loss\u001b[38;5;241m.\u001b[39mitem())\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/_tensor.py:307\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    300\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    301\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    305\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[1;32m    306\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[0;32m--> 307\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/autograd/__init__.py:154\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retain_graph \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    152\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m--> 154\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model2 = Model(100, 200, 2, g.etypes)\n",
    "opt = torch.optim.Adam(model.parameters())\n",
    "for epoch in range(1000):\n",
    "    logits = model2(g, node_features,'links')\n",
    "    #acc = (round(pred) == labels).float().sum() / len(logits)\n",
    "    #float_logits = logits.float()\n",
    "    #float_label = label.long()\n",
    "    #loss = nn.CrossEntropyLoss()\n",
    "    #crossentropyloss=nn.CrossEntropyLoss()\n",
    "    #crossentropyloss_output=crossentropyloss(logits, label)\n",
    "    logits =  logits.squeeze()\n",
    "    loss = torch.nn.BCEWithLogitsLoss(reduction='sum')(logits[train_mask], label[train_mask])\n",
    "    opt.zero_grad()\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0710, -0.1623, -0.1503,  ..., -0.1170, -0.0886, -0.0886],\n",
       "       grad_fn=<SqueezeBackward0>)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 0,  ..., 0, 1, 1])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " float_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'astype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[66], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mlogits\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m(FloatTensor)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'astype'"
     ]
    }
   ],
   "source": [
    "logits.astype(FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 0.,  ..., 0., 1., 1.])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
